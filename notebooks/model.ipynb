{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(os.path.join(project_root, \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from monai.losses import DiceLoss\n",
    "from monai.networks.nets import SegResNet\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "# The input data must have a shape of (B, N, H, W, D) format\n",
    "# * B - batch size\n",
    "# * N - number of classes\n",
    "# * H - height\n",
    "# * W - width\n",
    "# * D - depth\n",
    "class SegResModel(pl.LightningModule):\n",
    "    def __init__(self, in_channels, out_channels, learning_rate=1e-3):\n",
    "        super(SegResModel, self).__init__()\n",
    "        self.model = SegResNet(in_channels=in_channels, out_channels=out_channels)\n",
    "        self.dice_loss = DiceLoss(softmax=True)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch: Tuple[Tensor, Tensor], batch_idx: int) -> Tensor:\n",
    "        loss, _ = self._common_step(batch, batch_idx)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch: Tuple[Tensor, Tensor], batch_idx: int):\n",
    "        loss, _ = self._common_step(batch, batch_idx)\n",
    "        return loss\n",
    "\n",
    "    def _common_step(\n",
    "        self, batch: Tuple[Tensor, Tensor], batch_idx: int\n",
    "    ) -> Tuple[Tensor, Tensor]:\n",
    "        images, labels = batch\n",
    "        preds = self.forward(images)\n",
    "        loss = self.dice_loss(preds, labels)\n",
    "        return loss, preds\n",
    "\n",
    "    def predict_step(self, batch: Tensor, batch_idx: int) -> Tuple[Tensor, Tensor]:\n",
    "        images, labels = batch\n",
    "        preds = self.forward(images)\n",
    "        return preds, labels\n",
    "\n",
    "    def configure_optimizers(self) -> torch.optim.Optimizer:\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel(pl.LightningModule):\n",
    "    def __init__(self, model_list, num_classes):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self.models = model_list\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Collect predictions from each model in the ensemble\n",
    "        predictions = [model(x) for model in self.models]\n",
    "        # Average predictions\n",
    "        averaged_prediction = torch.mean(torch.stack(predictions), dim=0)\n",
    "        return averaged_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Module Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import BrainTumourDataModule, BrainTumourDataset\n",
    "\n",
    "image_path = \"../data/BrainTumourData/imagesTr/\"\n",
    "label_path = \"../data/BrainTumourData/labelsTr/\"\n",
    "data_module = BrainTumourDataModule(\n",
    "    data_path=image_path, seg_path=label_path, img_dim=(8, 8)\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/kristof/Melytanulas/medical-image-segmentation/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "/home/kristof/Melytanulas/medical-image-segmentation/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type      | Params | Mode \n",
      "------------------------------------------------\n",
      "0 | model     | SegResNet | 1.2 M  | train\n",
      "1 | dice_loss | DiceLoss  | 0      | train\n",
      "------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.706     Total estimated model params size (MB)\n",
      "137       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 328/328 [02:23<00:00,  2.29it/s, v_num=45]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 328/328 [02:23<00:00,  2.28it/s, v_num=45]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate each model\n",
    "segresnet = SegResModel(in_channels=2, out_channels=4)\n",
    "# model2 = SegResModel(in_channels=2, out_channels=4)\n",
    "\n",
    "# Train each model separately\n",
    "trainer = pl.Trainer(max_epochs=1)\n",
    "trainer.fit(segresnet, data_module)\n",
    "# trainer.fit(model2, data_module)\n",
    "\n",
    "# Create the ensemble model using the trained models\n",
    "# ensemble_model = EnsembleModel([segresnet], num_classes=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:34<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([59, 2, 8, 8, 128])\n",
      "torch.Size([59, 4, 8, 8, 128])\n",
      "torch.Size([59, 4, 8, 8, 128])\n"
     ]
    }
   ],
   "source": [
    "segresnet.eval()\n",
    "\n",
    "image_list: List[Tensor] = []\n",
    "prediction_list: List[Tensor] = []\n",
    "label_list: List[Tensor] = []\n",
    "\n",
    "for images, label in tqdm(data_module.test_dataloader()):\n",
    "    with torch.no_grad():\n",
    "        pred: Tensor = segresnet(images)\n",
    "        image_list.append(images)\n",
    "        prediction_list.append(pred)\n",
    "        label_list.append(label)\n",
    "\n",
    "images: Tensor = torch.cat(image_list, dim=0)\n",
    "predictions: Tensor = torch.cat(prediction_list, dim=0)\n",
    "labels: Tensor = torch.cat(label_list, dim=0)\n",
    "\n",
    "print(f\"images shape: {images.shape}\")\n",
    "print(f\"predictions shape: {predictions.shape}\")\n",
    "print(f\"labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib.axes import Axes\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def plot_slices(image: Tensor, label: Tensor, pred: Tensor, slice_index: int) -> None:\n",
    "    image_slice: np.ndarray = image[0, :, :, slice_index].cpu().numpy()\n",
    "    labels_map: Tensor = torch.argmax(label, dim=0)\n",
    "    preds_map: Tensor = torch.argmax(pred, dim=0)\n",
    "\n",
    "    labels_slice: np.ndarray = labels_map[:, :, slice_index].cpu().numpy()\n",
    "    preds_slice: np.ndarray = preds_map[:, :, slice_index].cpu().numpy()\n",
    "\n",
    "    axes: Tuple[Axes, Axes, Axes]\n",
    "    _, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    axes_orig: Axes = axes[0]\n",
    "    axes_truth: Axes = axes[1]\n",
    "    axes_pred: Axes = axes[2]\n",
    "\n",
    "    axes_orig.imshow(image_slice, cmap=\"gray\")\n",
    "    axes_orig.set_title(\"Original MRI Image\")\n",
    "    axes_orig.axis(\"off\")\n",
    "\n",
    "    axes_truth.imshow(labels_slice, cmap=\"jet\")\n",
    "    axes_truth.set_title(\"Ground Truth\")\n",
    "    axes_truth.axis(\"off\")\n",
    "\n",
    "    axes_pred.imshow(preds_slice, cmap=\"jet\")\n",
    "    axes_pred.set_title(\"Predictions\")\n",
    "    axes_pred.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([2, 8, 8, 128])\n",
      "labels shape: torch.Size([4, 8, 8, 128])\n",
      "preds shape: torch.Size([4, 8, 8, 128])\n"
     ]
    }
   ],
   "source": [
    "image = images[0]\n",
    "print(f\"image shape: {image.shape}\")\n",
    "\n",
    "label = labels[0]\n",
    "print(f\"labels shape: {label.shape}\")\n",
    "\n",
    "pred = predictions[0]\n",
    "print(f\"preds shape: {pred.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_slices(image, label, pred, slice_index=image.shape[3] // 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

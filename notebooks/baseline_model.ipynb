{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "sys.path.append(os.path.join(project_root, \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "class BaselineModel(pl.LightningModule):\n",
    "    def __init__(self) -> None:\n",
    "        super(BaselineModel, self).__init__()\n",
    "        self.mean_intensity = {\n",
    "            0: 0.0,\n",
    "            1: 0.0,\n",
    "            2: 0.0,\n",
    "            3: 0.0,\n",
    "        }\n",
    "        self.class_count = {\n",
    "            0: 0,\n",
    "            1: 0,\n",
    "            2: 0,\n",
    "            3: 0,\n",
    "        }\n",
    "\n",
    "    def forward(self, image_data: torch.Tensor) -> torch.Tensor:\n",
    "        image_data = image_data.cpu()\n",
    "\n",
    "        num_classes = len(self.mean_intensity)\n",
    "        mean_intensities = np.array(list(self.mean_intensity.values()))\n",
    "        image = image_data[:, :, :, 0].numpy()\n",
    "\n",
    "        pixel_classes = np.zeros(image.shape, dtype=int)\n",
    "\n",
    "        for class_index in range(num_classes):\n",
    "            pixel_classes[image > mean_intensities[class_index]] = class_index\n",
    "\n",
    "        pixel_classes[image <= np.mean(mean_intensities)] = 0\n",
    "\n",
    "        pixel_classes_one_hot = np.eye(num_classes)[pixel_classes]\n",
    "        pixel_classes_one_hot = np.moveaxis(pixel_classes_one_hot, -1, 1)\n",
    "\n",
    "        return torch.tensor(pixel_classes_one_hot, dtype=torch.float32)\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: list[Tuple[torch.Tensor, torch.Tensor]], batch_idx: int\n",
    "    ) -> None:\n",
    "        X, y = batch\n",
    "\n",
    "        flair_image: torch.Tensor = X[:, :, :, :, 0]\n",
    "\n",
    "        for class_index in self.mean_intensity.keys():\n",
    "            class_mask = y[:, :, class_index, :, :]\n",
    "\n",
    "            class_pixels = flair_image[class_mask == 1]\n",
    "\n",
    "            self.class_count[class_index] += class_pixels.numel()\n",
    "\n",
    "            self.mean_intensity[class_index] += class_pixels.sum().item()\n",
    "\n",
    "    def validation_step(\n",
    "        self, batch: list[Tuple[torch.Tensor, torch.Tensor]], batch_idx: int\n",
    "    ) -> None:\n",
    "        return\n",
    "\n",
    "    def configure_optimizers(self) -> None:\n",
    "        return\n",
    "\n",
    "    def on_train_end(self) -> None:\n",
    "        self._calculate_mean_intensity()\n",
    "\n",
    "    def _calculate_mean_intensity(self) -> None:\n",
    "        for class_index in self.mean_intensity.keys():\n",
    "            if self.class_count[class_index] > 0:\n",
    "                self.mean_intensity[class_index] /= self.class_count[class_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import BrainTumourDataModule\n",
    "\n",
    "data_module = BrainTumourDataModule(\"../BrainTumourData/imagesTr/\")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "test_data = None\n",
    "ground_truth = None\n",
    "for batch in data_module.train_dataloader():\n",
    "    X, y = batch\n",
    "    X, y = X[0], y[0]\n",
    "    test_data = X\n",
    "    ground_truth = y\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_data[50, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(logger=False, enable_checkpointing=False, max_epochs=1)\n",
    "model = BaselineModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_dataloaders=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(2, 4, figsize=(15, 7))\n",
    "\n",
    "index_to_name = {\n",
    "    0: \"Background\",\n",
    "    1: \"Edema\",\n",
    "    2: \"Non-Enhancing Tumor\",\n",
    "    3: \"Enhancing Tumor\",\n",
    "}\n",
    "\n",
    "for class_index in range(4):\n",
    "    axs[0, class_index].imshow(output[50, class_index, :, :])\n",
    "    axs[0, class_index].set_title(f\"Prediction - Class {index_to_name[class_index]}\")\n",
    "    axs[0, class_index].axis(\"off\")\n",
    "\n",
    "    axs[1, class_index].imshow(ground_truth[50, class_index, :, :])\n",
    "    axs[1, class_index].set_title(f\"Ground Truth - Class {index_to_name[class_index]}\")\n",
    "    axs[1, class_index].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model.eval()\n",
    "\n",
    "total_batches = len(data_module.test_dataloader())\n",
    "num_classes = 4\n",
    "height, width = 128, 128\n",
    "slices_per_sample = 155\n",
    "\n",
    "all_predictions = torch.empty(\n",
    "    (total_batches, slices_per_sample, num_classes, height, width), dtype=torch.float32\n",
    ")\n",
    "all_targets = torch.empty(\n",
    "    (total_batches, slices_per_sample, num_classes, height, width), dtype=torch.float32\n",
    ")\n",
    "\n",
    "for current_index, (images, targets) in enumerate(data_module.test_dataloader()):\n",
    "    with torch.no_grad():\n",
    "        predictions = model(images[0])\n",
    "        all_predictions[current_index] = predictions\n",
    "        all_targets[current_index] = targets[0]\n",
    "\n",
    "print(\"Shape of all_predictions:\", all_predictions.shape)\n",
    "print(\"Shape of all_targets:\", all_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import *\n",
    "\n",
    "dice_scores = dice_score(all_predictions, all_targets)\n",
    "mean_dsc = mean_dice_score(dice_scores)\n",
    "recall_scores, precision_scores = recall_precision(all_predictions, all_targets)\n",
    "weighted_recall_score = weighted_recall(recall_scores, alpha=[0.2, 0.3, 0.5])\n",
    "\n",
    "print(\"Dice Scores for each class:\", dice_scores)\n",
    "print(\"Mean Dice Score:\", mean_dsc)\n",
    "print(\"Recall Scores for each class:\", recall_scores)\n",
    "print(\"Precision Scores for each class:\", precision_scores)\n",
    "print(\"Weighted Recall:\", weighted_recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = compute_confusion_matrix(all_predictions, all_targets)\n",
    "print(\"Confusion Matrix:\", confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
